# hello_pytorch_gpu.sub
# Submit file to access the GPU

# set the log, error and output files
log = hello_pytorch_gpu_pixi-pack.log.txt
error = hello_pytorch_gpu_pixi-pack.err.txt
output = hello_pytorch_gpu_pixi-pack.out.txt

# set the executable to run
executable = hello_pytorch_gpu_pixi-pack.sh
arguments = $(Process)

# transfer training data files to the compute node
transfer_input_files = osdf:///chtc/staging/mfeickert/envs/hello_pytorch/hello-pytorch-environment-b8dd14a4.sh, MNIST_data.tar.gz, ../../src/torch_detect_GPU.py, ../../src/torch_MNIST.py

# transfer the serialized trained model back
transfer_output_files = mnist_cnn.pt

should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# We require a machine with a modern version of the CUDA driver
Requirements = (Target.CUDADriverVersion >= 12.0)

# We must request 1 CPU in addition to 1 GPU
request_cpus = 1
request_gpus = 1

# select some memory and disk space
# Need larger memory and disk than normal as need to accommodate the environment being unpacked
request_memory = 10GB
request_disk = 14GB

# Opt in to using CHTC GPU Lab resources
+WantGPULab = true
# Specify short job type to run more GPUs in parallel
# Can also request "medium" or "long"
+GPUJobLength = "short"

# Tell HTCondor to run 1 instances of our job:
queue 1
