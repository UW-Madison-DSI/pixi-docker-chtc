# Running the Hello PyTorch example on CHTC GPUs with Linux containers

Examples are provided for running on GPUs with both Docker containers (under `docker/`) and Apptainer containers (under `apptainer/`).

### Resources

CHTC's documentation has good resources on how to effectively use GPU resources on CHTC.

* [Use GPUS](https://chtc.cs.wisc.edu/uw-research-computing/gpu-jobs)
* [Explore and Test Docker Containers](https://chtc.cs.wisc.edu/uw-research-computing/docker-test.html)
* [Use an Apptainer Container in HTC Jobs](https://chtc.cs.wisc.edu/uw-research-computing/apptainer-htc#use-an-apptainer-container-in-htc-jobs)
* [HTCondor Documentation "Commands for Matchmaking" section with GPU specific arguments](https://htcondor.readthedocs.io/en/latest/man-pages/condor_submit.html#gpus_minimum_memory)
* [Modal's GPU Glossary section on 'Compute Capability'](https://modal.com/gpu-glossary/device-software/compute-capability#gpu-glossary)
